{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "PDF_DIR = '/med/pdbrepo/pdb_pubmed_pdfs/pdfs'\n",
    "TXT_DIR = '/med/pdbrepo/pdb_pubmed_pdfs/txts'\n",
    "PUBMED_PDF_CSV = '/med/pdbrepo/pdb_pubmed_pdfs/pmids.csv'\n",
    "TECHNIQUES_FILE = 'biochemical_techniques_list.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_txt(path, pages=None):\n",
    "    with StringIO() as output:\n",
    "        manager = PDFResourceManager()\n",
    "        \n",
    "        with TextConverter(manager, output, laparams=LAParams()) as converter:\n",
    "            interpreter = PDFPageInterpreter(manager, converter)\n",
    "\n",
    "            with open(path, 'rb') as infile:\n",
    "                for page in PDFPage.get_pages(infile, set()):\n",
    "                    interpreter.process_page(page)\n",
    "\n",
    "        text = output.getvalue()\n",
    "    \n",
    "    return text.replace(\"\\n\", \" \").replace(\"- \", \"\")\n",
    "\n",
    "\n",
    "def create_regex_dict_from_phrases(phrase_list):\n",
    "    phrase_regex_dict = {}\n",
    "    \n",
    "    for phrase in phrase_list:\n",
    "        phrase_regex_dict[phrase] = re.compile(phrase, re.IGNORECASE)\n",
    "        \n",
    "    return phrase_regex_dict\n",
    "\n",
    "\n",
    "def check_if_text_contains_phrases(pubmed_id, text, phrase_regex_dict):\n",
    "    hit_dict = {}\n",
    "    hit_dict[\"PubMed id\"] = pubmed_id\n",
    "    hit_dict[\"Total number of phrases found\"] = 0\n",
    "    hit_sum = 0\n",
    "    \n",
    "    for phrase in phrase_regex_dict.keys():\n",
    "        is_hit = re.search(phrase_regex_dict[phrase], text) is not None\n",
    "        hit_dict[phrase] = [1 if is_hit else 0]\n",
    "        \n",
    "        if is_hit:\n",
    "            hit_sum += 1\n",
    "        \n",
    "    hit_dict[\"Total number of phrases found\"] = hit_sum\n",
    "    hit_df = pd.DataFrame(hit_dict)\n",
    "    hit_df = hit_df.set_index(\"PubMed id\")\n",
    "        \n",
    "    return hit_df\n",
    "\n",
    "\n",
    "def get_pdf_text(pubmed_id, pdf_path):\n",
    "    txt_path = os.path.join(TXT_DIR, pubmed_id + \".txt\")\n",
    "    \n",
    "    if os.path.exists(txt_path):\n",
    "        with open(txt_path, \"r\") as text_file:\n",
    "            pdf_text = text_file.read()\n",
    "    else:\n",
    "        pdf_text = convert_pdf_to_txt(pdf_path)\n",
    "        with open(txt_path, \"w\") as text_file:\n",
    "            text_file.write(pdf_text)\n",
    "            \n",
    "    return pdf_text\n",
    "\n",
    "def analyze_pdf(pdf, phrase_regex_dict):\n",
    "    try:\n",
    "        pubmed_id = pdf.split('/')[-1][:-4]\n",
    "        pdf_text = get_pdf_text(pubmed_id, pdf)\n",
    "        hit_df = check_if_text_contains_phrases(pubmed_id, pdf_text, phrase_regex_dict)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        rai\n",
    "        hit_df = None\n",
    "    \n",
    "    return hit_df\n",
    "\n",
    "\n",
    "def analyze_pdfs(pdfs, phrases_list, max_count=None, n_jobs=1):\n",
    "    result_df = pd.DataFrame()\n",
    "    phrase_regex_dict = create_regex_dict_from_phrases(phrases_list)\n",
    "\n",
    "    if max_count is not None and max_count != -1:\n",
    "        pdfs = pdfs[:max_count]\n",
    "    \n",
    "    hit_dfs = Parallel(n_jobs=n_jobs)(delayed(analyze_pdf)(pdf, phrase_regex_dict) \n",
    "                                      for pdf in tqdm(pdfs))\n",
    "\n",
    "    return pd.concat(hit_dfs)\n",
    "\n",
    "def read_pmid_csv(csv_filename):\n",
    "    df = pd.read_csv(csv_filename, keep_default_na=False, na_values=[\"\", '\"\"'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_pdfs = glob.glob(f'{PDF_DIR}/*.pdf') \n",
    "with open(TECHNIQUES_FILE) as file:\n",
    "    techniques_list = file.read().rstrip().lower().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11357b3188c94952b57c01fb522e59f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df = analyze_pdfs(pubmed_pdfs, techniques_list, max_count=1000, n_jobs=4)\n",
    "result_df.to_csv(\"pdf_phrases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv(\"pdf_phrases.csv\", index_col=0)\n",
    "pubmed_df = read_pmid_csv(PUBMED_PDF_CSV)\n",
    "pubmed_df = pubmed_df.set_index(\"PubMed id\")\n",
    "\n",
    "combined_df = pubmed_df.join(result_df, how=\"inner\")\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"Publication year\", y=\"Total number of phrases found\", data=combined_df)\n",
    "plt.ylabel(\"Average number of phrases found\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
